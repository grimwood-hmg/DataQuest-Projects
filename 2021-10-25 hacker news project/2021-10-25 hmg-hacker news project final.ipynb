{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b25ef85b",
   "metadata": {},
   "source": [
    "# A brief look at Hacker News engagement\n",
    "## Hacker News can be found here: https://news.ycombinator.com/\n",
    "\n",
    "This will be a brief look at how engagement compares among Ask HN, Show HN, and other posts. This brief will also examine how, or if, time of day impacts engagement.\n",
    "\n",
    "Hacker News enables users to post and share content on the platform. Users can upvote and downvote submissions, resulting in a point count. It is similar to Reddit.\n",
    "\n",
    "Ask HN posts are a format in which users submit questions for the community to answer.\n",
    "\n",
    "Answers sought:\n",
    "* Do Ask HN or Show HN posts receive more comments on average?\n",
    "* Do posts created at a certain time receive more comments on average?\n",
    "\n",
    "This analysis will be done in two parts:\n",
    "* Exclusion of zero-comment posts, ie posts with low to no engagement.\n",
    "* Inclusion of zero-comment posts, ie posts with low to no engagement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a18f7a",
   "metadata": {},
   "source": [
    "## Looking at engagement via comments and points\n",
    "### Exclusion of zero-comment posts\n",
    "|Post Type |Post Count |Average Comments |Average Points \n",
    "| :--- | :--- | :--- | :--- |\n",
    "|Ask HN |6,911 |13.74 |14.40\n",
    "|Show HN |5,059 |9.81 |26.62\n",
    "|Others |68,431 |25.84 |53.43\n",
    "|Total |80,401 |23.79 |48.39\n",
    "\n",
    "### Inclusion of zero-comment posts\n",
    "|Post Type |Post Count |Average Comments |Average Points\n",
    "| --- | --- | --- | --- \n",
    "|Ask HN |9,139 |10.39 |11.31\n",
    "|Show HN |10,158 |4.89 |14.84\n",
    "|Others |273,822 |6.46 |15.16\n",
    "|Total |293,119 |6.53 |15.03\n",
    "\n",
    "#### Ask HN posts\n",
    "\"Ask HN\" posts have consistent average engagement on HackerNews. Including zero-comment submissions does not significantly depress the average comment and points counts. This indicates reliable engagement from the community in this style of post. However, based on averages, this engagement tends toward the low side when compared to the higher averages of \"Show HN\" posts and all other posts.\n",
    "\n",
    "Of all the Ask HN posts, about 75 percent of those received direct user engagement, or comments.\n",
    "\n",
    "Ask HN posts show the most consistent, direct engagement across the two categories. These posts generally represent a \"safe bet\" for creating a post that receives engagement from other users. \n",
    "\n",
    "#### Show HN\n",
    "Show HN posts represent relatively low, direct engagement, but show potential for receiving points. This means that there is moderate potential to have eyeballs, followed by mouse clicks, on a post in this category.\n",
    "\n",
    "Show HN posts are nearer a coin-flip of whether a user will directly engage with the post. About 50 percent of Show HN posts received engagement.\n",
    "\n",
    "#### Other posts\n",
    "Posts in the \"others\" category, i.e. non-Ask and non-Show HN posts, have strong potential for average high engagement. \n",
    "\n",
    "However, there is a stark contrast in average engagement between the two analyses. There is a strong possibility that a post in the Show HN and Others categories will receive low to no engagement both in terms of comments and accrued points. When including zero-comment posts in the analysis, there is significant depression in comment and points averages when compared to the exclusionary analysis.\n",
    "\n",
    "Posts in the \"other\" category have the potential for the highest engagement but represent a significant gamble. Only about 30 percent of those posts received direct engagement.\n",
    "\n",
    "#### The highest number of comments an individual post received: \n",
    "* Ask HN: 1,007 comments:\n",
    "    * ['11814828', 'Ask HN: Who is hiring? (June 2016)', '', '644', '1007', 'whoishiring', '6/1/2016 15:01']\n",
    "* Show HN: 306 comments:\n",
    "    * ['11667494', 'Show HN: BitKeeper  Enterprise-ready version control, now open-source', 'https://www.bitkeeper.org/', '384', '306', 'wscott', '5/10/2016 14:39']\n",
    "* Other: 2,531 comments:\n",
    "    * ['11966167', 'UK votes to leave EU', 'http://www.bbc.co.uk/news/uk-politics-36615028', '3125', '2531', 'dmmalam', '6/24/2016 3:48']\n",
    "\n",
    "#### The highest number of comments an individual post received: \n",
    "* Ask HN: 644 points:\n",
    "    * ['11814828', 'Ask HN: Who is hiring? (June 2016)', '', '644', '1007', 'whoishiring', '6/1/2016 15:01']\n",
    "* Show HN: 384 points:\n",
    "    * ['11667494', 'Show HN: BitKeeper  Enterprise-ready version control, now open-source', 'https://www.bitkeeper.org/', '384', '306', 'wscott', '5/10/2016 14:39']\n",
    "* Other: 3,125 points:\n",
    "    * ['11966167', 'UK votes to leave EU', 'http://www.bbc.co.uk/news/uk-politics-36615028', '3125', '2531', 'dmmalam', '6/24/2016 3:48']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932552a3",
   "metadata": {},
   "source": [
    "## Timing for engagement\n",
    "\n",
    "Below are several tables for timing engagement. The tables include one column for the hour of the day, in 24-hour format and in Eastern timezone. This represents the average number of comments and points post types receive based on the time of day.\n",
    "\n",
    "#### Ask HN\n",
    "Ask HN posts tend to receive comments and up/downvotes during the early afternoon hours, peaking about 3 p.m. (or 15:00). It generally starts about noon and trails off about the end of the workday, 5 p.m. (or 17:00).\n",
    "\n",
    "There are outliers in the averages: 10 a.m. (10:00) and 2 a.m. (02:00).\n",
    "\n",
    "#### Show HN\n",
    "Show HN posts are not as easily generalized. However, data suggests these types of posts receive engagement during the early morning hours, before the start of the workday; about noon, as people are about to have lunch or during lunch; and at the end of the workday. There are some outliers indicating engagement in the later hours: around the time people may be eating dinner and before bed.\n",
    "\n",
    "#### Other\n",
    "Other posts show direct engagement starting prior to lunch and peaking at the end of lunch, about 1 p.m. (or 13:00). Engagement in terms of up/downvoting is generally consistent through the afternoon. \n",
    "\n",
    "This picture is less clear, however, when looking over the dataset that includes zero-comment posts. Lunchtimes, 11 a.m. (or 11:00) to 1 p.m. (13:00) show high engagement among that dataset.\n",
    "\n",
    "\n",
    "#### All\n",
    "\n",
    "### Excludes zero-comment posts\n",
    "#### Hours of high-average, direct engagement (comments)\n",
    "|Hour |Ask HN |Hour |Show HN |Hour |Others |Hour |All\n",
    "|---:|:---|---:|:---|---:|:---|---:|:---|\n",
    "|15:00 |39.67|07:00 |12.42|13:00 |29.37|15:00 |27.63|\n",
    "|13:00 |22.22|12:00 |12.03|12:00 |29.20|13:00 |27.31|\n",
    "|12:00 |15.45|14:00 |11.60|14:00 |28.09|12:00 |26.76|\n",
    "|10:00 |13.76|08:00 |11.07|15:00 |27.97|14:00 |25.66|\n",
    "|17:00 |13.73|04:00 |10.87|11:00 |27.13|11:00 |24.62|\n",
    "\n",
    "#### Hours of high-average engagement (points)\n",
    "| Hour | Ask HN | Hour | Show HN | Hour | Others | Hour | All   |\n",
    "|------|--------|------|---------|------|--------|------|-------|\n",
    "| 15:00| 29.31  | 12:00| 33.57   | 13:00| 58.62  | 13:00| 53.61 |\n",
    "| 13:00| 23.77  | 11:00| 31.57   | 12:00| 57.53  | 12:00| 52.49 |\n",
    "| 17:00| 16.96  | 23:00| 30.40   | 15:00| 55.95  | 15:00| 51.11 |\n",
    "| 10:00| 16.71  | 19:00| 29.80   | 17:00| 55.64  | 17:00| 50.46 |\n",
    "| 12:00| 16.53  | 06:00| 29.38   | 16:00| 55.62  | 16:00| 50.00 |\n",
    "\n",
    "### Includes zero-comment posts\n",
    "#### Hours of high-average, direct engagement (comments)\n",
    "| Hour | Ask HN | Hour | Show HN | Hour | Others | Hour | All  |\n",
    "|------|--------|------|---------|------|--------|------|------|\n",
    "| 15:00| 28.68  | 12:00| 6.99    | 12:00| 7.59   | 12:00| 7.69 |\n",
    "| 13:00| 16.32  | 07:00| 6.68    | 11:00| 7.37   | 11:00| 7.37 |\n",
    "| 12:00| 12.38  | 11:00| 6.00    | 02:00| 7.18   | 13:00| 7.34 |\n",
    "| 02:00| 11.14  | 08:00| 5.60    | 13:00| 7.15   | 02:00| 7.27 |\n",
    "| 10:00| 10.68  | 14:00| 5.52    | 05:00| 6.79   | 15:00| 7.05 |\n",
    "\n",
    "#### Hours of average engagement (comments)\n",
    "| Hour  | Ask HN | Hour  | Show HN | Hour  | Others | Hour  | All   |\n",
    "|-------|--------|-------|---------|-------|--------|-------|-------|\n",
    "| 15:00 | 21.64  | 12:00 | 20.91   | 02:00 | 16.71  | 12:00 | 16.79 |\n",
    "| 13:00 | 17.93  | 11:00 | 19.26   | 12:00 | 16.70  | 02:00 | 16.41 |\n",
    "| 12:00 | 13.58  | 13:00 | 17.02   | 11:00 | 16.29  | 11:00 | 16.19 |\n",
    "| 10:00 | 13.44  | 19:00 | 16.06   | 00:00 | 16.12  | 13:00 | 16.11 |\n",
    "| 17:00 | 12.19  | 06:00 | 15.99   | 13:00 | 16.02  | 00:00 | 15.88 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e045a5",
   "metadata": {},
   "source": [
    "## Answering the questions\n",
    "* Do Ask HN or Show HN posts receive more comments on average?\n",
    "An \"other\" post has the potential for the highest engagement. This is evidenced by the high-end average number of comments and points. However, only 1-in-4 of those posts received any direct engagement.\n",
    "\n",
    "\"Ask HN\" posts show the most consistent engagement.\n",
    "\n",
    "* Do posts created at a certain time receive more comments on average?\n",
    "Three o'clock in the afternoon is the most consistent time for high average user engagement across categories, give or take an hour. Users are, generally, engaging with Ask, Show, and other posts during the afternoon hours. Secondarily, there is notable engagement around noon (11 a.m. to 1 p.m.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2023b26d",
   "metadata": {},
   "source": [
    "## The data and methods\n",
    "\n",
    "The data was sourced through [Kaggle.com](https://www.kaggle.com/hacker-news/hacker-news-posts). It was provided through a guided project in the DataQuest.io curriculum for data analysis in Python. The user who posted the dataset states that the data was scraped from HackerNews using a tool [available via GitHub](https://github.com/minimaxir/get-all-hacker-news-submissions-comments).\n",
    "\n",
    "The dataset covers September 2015 through September 2016. There were approximately 293,000 entries. \n",
    "\n",
    "It includes the following columns:\n",
    "* id: a unique identification number per post\n",
    "* title: title of the post\n",
    "* url: the URL of the item being linked to\n",
    "* num_points: the number of upvotes the post received\n",
    "* num_comments: the number of comments the post received\n",
    "* author: the name of the account that made the post\n",
    "* created_at: the date and time the post was made (the time zone is Eastern Time in the US)\n",
    "\n",
    "Several functions are defined in the code block below for opening the dataset, exploring it, and checking for errant entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb586256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions for exploration\n",
    "\n",
    "## open a csv file\n",
    "# a function to open datasets\n",
    "# returns the data set and header row or\n",
    "# returns the dataset nested list\n",
    "# recommended manner to call function:\n",
    "# variable_data, header_data = open_dataset('filename')\n",
    "def open_dataset(file_name, has_head=True):\n",
    "    opened_file = open(file_name)\n",
    "    from csv import reader\n",
    "    read_file = reader(opened_file)\n",
    "    data = list(read_file)\n",
    "    if has_head:\n",
    "        return data[1:], data[0]\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "# explores a dataset\n",
    "# prints five rows of the set, number columns, number of rows\n",
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row, '\\n')\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))\n",
    "        \n",
    "# checks for shifted columns in a dataset\n",
    "# see https://community.dataquest.io/t/guided-project-finding-insights-about-popular-hacker-news-posts/557800\n",
    "def check_shifted(header, dataset):\n",
    "    header_len = len(header)\n",
    "    error_count = 0\n",
    "    for row in dataset:\n",
    "        if len(row) != header_len:\n",
    "            error_count += 1\n",
    "            print(header, '\\n')\n",
    "            print('Row Index: ', dataset.index(row), '\\n')\n",
    "            print(row, '/n')\n",
    "    print('Column Shift Errors: ', error_count)\n",
    "\n",
    "# checks for null or missing data\n",
    "# see https://community.dataquest.io/t/guided-project-finding-insights-about-popular-hacker-news-posts/557800\n",
    "def check_null_data(dataset_header, dataset, index):\n",
    "    null_value = False\n",
    "    null_count = 0\n",
    "    # Loop over each row in the dataset to identify any missing values at the given index\n",
    "    \n",
    "    for row in dataset:\n",
    "        if row[index] == '':\n",
    "            null_value = True\n",
    "            null_count += 1\n",
    "        if null_value == True:\n",
    "            print(dataset_header, '\\n')\n",
    "            print('Row Index: ', dataset.index(row), '\\n') # Print the row number where the error was found\n",
    "            print(row, '\\n')\n",
    "            null_value = False\n",
    "    # Print the number of missing values identified at the given index\n",
    "    print('Missing \"{}\" Values Identified: {}'.format(hn_header[index], null_count)) #uses object defined outside of function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "62de4b75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'] \n",
      "\n",
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'] \n",
      "\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'] \n",
      "\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'] \n",
      "\n",
      "['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16'] \n",
      "\n",
      "['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14'] \n",
      "\n",
      "Number of rows: 293119\n",
      "Number of columns: 7\n",
      "\n",
      "\n",
      "Column Shift Errors:  0\n",
      "Missing \"num_points\" Values Identified: 0\n",
      "Missing \"num_comments\" Values Identified: 0\n",
      "Missing \"created_at\" Values Identified: 0\n"
     ]
    }
   ],
   "source": [
    "#using the open_dataset function\n",
    "hn, hn_header = open_dataset(file_name='HN_posts_year_to_Sep_26_2016.csv')\n",
    "\n",
    "print(hn_header, '\\n')\n",
    "explore_data(hn, 0, 5, True)\n",
    "print('\\n')\n",
    "check_shifted(hn_header, hn)\n",
    "check_null_data(hn_header, hn, 3)\n",
    "check_null_data(hn_header, hn, 4)\n",
    "check_null_data(hn_header, hn, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366960aa",
   "metadata": {},
   "source": [
    "## Filtering the data\n",
    "\n",
    "In the code block below, the dataset is divvied into two sets of nested lists and averages are calculated for comments and points.\n",
    "\n",
    "The nested lists include:\n",
    "* Ask HN: a list of all Ask HN posts.\n",
    "* Show HN: a list of all Show HN posts\n",
    "* Other: a list of all non-Ask and non-Show posts\n",
    "* All: A list of all the posts.\n",
    "\n",
    "These lists were duplicated to analyze with the inclusion and exclusion of zero-comment posts.\n",
    "\n",
    "The next code block is used to output the initial calculations into easy-to-read formats. That output was used for the above analyses. It includes excerpts from each list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "deaa4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering the data\n",
    "# four lists to separate ask, show, others, and all posts\n",
    "# 'other' posts consist of all non-ask and show posts.\n",
    "\n",
    "# collects posts with comments\n",
    "def commented_posts(dataset, index):\n",
    "    output = []\n",
    "    for row in dataset:\n",
    "        num_comments = int(row[index])\n",
    "        if num_comments != 0:\n",
    "            output.append(row)\n",
    "    return output\n",
    "\n",
    "#calc avg\n",
    "def average_calc(dataset, index):\n",
    "    total = 0\n",
    "    for item in dataset:\n",
    "        total += int(item[index])    \n",
    "    return total / len(dataset)\n",
    "\n",
    "# collect user submissions by title\n",
    "def collect_titles(dataset, index):\n",
    "    ask_posts = []\n",
    "    show_posts = []\n",
    "    other_posts = []\n",
    "    for row in dataset:\n",
    "        title = row[index]\n",
    "        title = title.lower()\n",
    "        if title.startswith('ask hn'):\n",
    "            ask_posts.append(row)\n",
    "        elif title.startswith('show hn'):\n",
    "            show_posts.append(row)\n",
    "        else:\n",
    "            other_posts.append(row)\n",
    "    return ask_posts, show_posts, other_posts\n",
    "    \n",
    "ask_posts, show_posts, other_posts = collect_titles(hn, 1) # collects posts into three list obj that \n",
    "#includes all posts, including those without engagement\n",
    "\n",
    "## excludes posts without comments/engagement\n",
    "ask_comments = commented_posts(ask_posts, 4)\n",
    "show_comments = commented_posts(show_posts, 4)\n",
    "other_comments = commented_posts(other_posts, 4)\n",
    "hn_comments = commented_posts(hn, 4) # all posts with engagement\n",
    "# avg comments check\n",
    "avg_ask_comments = average_calc(ask_comments, 4)\n",
    "avg_show_comments = average_calc(show_comments, 4)\n",
    "avg_other_comments = average_calc(other_comments, 4)\n",
    "hn_avg_comments = average_calc(hn_comments, 4) # avg comments of all posts with engagement\n",
    "\n",
    "## includes posts without engagement\n",
    "# average number of comments check\n",
    "avg_ask_posts = average_calc(ask_posts, 4)\n",
    "avg_show_posts = average_calc(show_posts, 4)\n",
    "avg_other_posts = average_calc(other_posts, 4)\n",
    "avg_all = average_calc(hn, 4) # avg comments of all posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49a89f82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the scraped data, excluding posts without direct engagement, there are 6,911 \"Ask HN\" posts, 5,059 \"Show HN\" posts, 68,431 \"other posts\", and a total of 80,401 posts. \n",
      "\n",
      "\n",
      "\n",
      "An overview of posts, excluding posts without direct engagement:\n",
      "Ask HN posts: 6,911\n",
      "Ask HN average comments: 13.74\n",
      "Ask HN average points: 14.40\n",
      "['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53']\n",
      "['12578522', 'Ask HN: How do you pass on your work when you die?', '', '6', '3', 'PascLeRasc', '9/26/2016 1:17']\n",
      "['12577870', 'Ask HN: Why join a fund when you can be an angel?', '', '1', '3', 'anthony_james', '9/25/2016 22:48']\n",
      "['12577647', 'Ask HN: Someone uses stock trading as passive income?', '', '5', '2', '00taffe', '9/25/2016 21:50']\n",
      "['12576946', 'Ask HN: How hard would it be to make a cheap, hackable phone?', '', '2', '1', 'hkt', '9/25/2016 19:30']\n",
      "\n",
      "\n",
      "Show HN posts: 5,059\n",
      "Show HN average comments: 9.81\n",
      "Show HN average points: 26.62\n",
      "['12577142', 'Show HN: Jumble  Essays on the go #PaulInYourPocket', 'https://itunes.apple.com/us/app/jumble-find-startup-essay/id1150939197?ls=1&mt=8', '1', '1', 'ryderj', '9/25/2016 20:06']\n",
      "['12576813', 'Show HN: Learn Japanese Vocab via multiple choice questions', 'http://japanese.vul.io/', '1', '1', 'soulchild37', '9/25/2016 19:06']\n",
      "['12576090', 'Show HN: Markov chain Twitter bot. Trained on comments left on Pornhub', 'https://twitter.com/botsonasty', '3', '1', 'keepingscore', '9/25/2016 16:50']\n",
      "['12575471', 'Show HN: Project-Okot: Novel, CODE-FREE data-apps in mere seconds', 'https://studio.nuchwezi.com/', '3', '1', 'nfixx', '9/25/2016 14:30']\n",
      "['12574773', 'Show HN: Cursor that Screenshot', 'http://edward.codes/cursor-that-screenshot', '3', '3', 'ed-bit', '9/25/2016 10:50']\n",
      "\n",
      "\n",
      "Other posts: 68,431\n",
      "Other average comments: 25.84\n",
      "Other posts average points: 53.43\n",
      "['12578975', 'Saving the Hassle of Shopping', 'https://blog.menswr.com/2016/09/07/whats-new-with-your-style-feed/', '1', '1', 'bdoux', '9/26/2016 3:13']\n",
      "['12578822', 'Amazons Algorithms Dont Find You the Best Deals', 'https://www.technologyreview.com/s/602442/amazons-algorithms-dont-find-you-the-best-deals/', '1', '1', 'yarapavan', '9/26/2016 2:26']\n",
      "['12578694', 'Emergency dose of epinephrine that does not cost an arm and a leg', 'http://m.imgur.com/gallery/th6Ua', '2', '1', 'dredmorbius', '9/26/2016 1:54']\n",
      "['12578624', 'Phone Makers Could Cut Off Drivers. So Why Dont They?', 'http://www.nytimes.com/2016/09/25/technology/phone-makers-could-cut-off-drivers-so-why-dont-they.html', '4', '1', 'danso', '9/26/2016 1:37']\n",
      "['12578556', 'OpenMW, Open Source Elderscrolls III: Morrowind Reimplementation', 'https://openmw.org/en/', '32', '3', 'rocky1138', '9/26/2016 1:24']\n",
      "\n",
      "\n",
      "All posts: 80,401\n",
      "All posts average comments: 23.79\n",
      "All posts average points: 48.39\n",
      "['12578975', 'Saving the Hassle of Shopping', 'https://blog.menswr.com/2016/09/07/whats-new-with-your-style-feed/', '1', '1', 'bdoux', '9/26/2016 3:13']\n",
      "['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53']\n",
      "['12578822', 'Amazons Algorithms Dont Find You the Best Deals', 'https://www.technologyreview.com/s/602442/amazons-algorithms-dont-find-you-the-best-deals/', '1', '1', 'yarapavan', '9/26/2016 2:26']\n",
      "['12578694', 'Emergency dose of epinephrine that does not cost an arm and a leg', 'http://m.imgur.com/gallery/th6Ua', '2', '1', 'dredmorbius', '9/26/2016 1:54']\n",
      "['12578624', 'Phone Makers Could Cut Off Drivers. So Why Dont They?', 'http://www.nytimes.com/2016/09/25/technology/phone-makers-could-cut-off-drivers-so-why-dont-they.html', '4', '1', 'danso', '9/26/2016 1:37']\n",
      "In the scraped data, including posts with no direct engagement, there are 9,139 \"Ask HN\" posts, 10,158 \"Show HN\" posts, 273,822 \"other posts\", and a total of 293,119 posts. \n",
      "\n",
      "An overview of posts, including posts without direct engagement:\n",
      "Ask HN posts: 9,139\n",
      "Ask HN average comments: 10.39\n",
      "Ask HN average points: 11.31\n",
      "['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53']\n",
      "['12578522', 'Ask HN: How do you pass on your work when you die?', '', '6', '3', 'PascLeRasc', '9/26/2016 1:17']\n",
      "['12577908', 'Ask HN: How a DNS problem can be limited to a geographic region?', '', '1', '0', 'kuon', '9/25/2016 22:57']\n",
      "['12577870', 'Ask HN: Why join a fund when you can be an angel?', '', '1', '3', 'anthony_james', '9/25/2016 22:48']\n",
      "['12577647', 'Ask HN: Someone uses stock trading as passive income?', '', '5', '2', '00taffe', '9/25/2016 21:50']\n",
      "\n",
      "\n",
      "Show HN posts: 10,158\n",
      "Show HN average comments: 4.89\n",
      "Show HN average points: 14.84\n",
      "['12578335', 'Show HN: Finding puns computationally', 'http://puns.samueltaylor.org/', '2', '0', 'saamm', '9/26/2016 0:36']\n",
      "['12578182', 'Show HN: A simple library for complicated animations', 'https://christinecha.github.io/choreographer-js/', '1', '0', 'christinecha', '9/26/2016 0:01']\n",
      "['12578098', 'Show HN: WebGL visualization of DNA sequences', 'http://grondilu.github.io/dna.html', '1', '0', 'grondilu', '9/25/2016 23:44']\n",
      "['12577991', 'Show HN: Pomodoro-centric, heirarchical project management with ES6 modules', 'https://github.com/jakebian/zeal', '2', '0', 'dbranes', '9/25/2016 23:17']\n",
      "['12577142', 'Show HN: Jumble  Essays on the go #PaulInYourPocket', 'https://itunes.apple.com/us/app/jumble-find-startup-essay/id1150939197?ls=1&mt=8', '1', '1', 'ryderj', '9/25/2016 20:06']\n",
      "\n",
      "\n",
      "Other posts: 273,822\n",
      "Other average comments: 6.46\n",
      "Other posts average points: 15.16\n",
      "['12578335', 'Show HN: Finding puns computationally', 'http://puns.samueltaylor.org/', '2', '0', 'saamm', '9/26/2016 0:36']\n",
      "['12578182', 'Show HN: A simple library for complicated animations', 'https://christinecha.github.io/choreographer-js/', '1', '0', 'christinecha', '9/26/2016 0:01']\n",
      "['12578098', 'Show HN: WebGL visualization of DNA sequences', 'http://grondilu.github.io/dna.html', '1', '0', 'grondilu', '9/25/2016 23:44']\n",
      "['12577991', 'Show HN: Pomodoro-centric, heirarchical project management with ES6 modules', 'https://github.com/jakebian/zeal', '2', '0', 'dbranes', '9/25/2016 23:17']\n",
      "['12577142', 'Show HN: Jumble  Essays on the go #PaulInYourPocket', 'https://itunes.apple.com/us/app/jumble-find-startup-essay/id1150939197?ls=1&mt=8', '1', '1', 'ryderj', '9/25/2016 20:06']\n",
      "\n",
      "\n",
      "All posts: 293,119\n",
      "All posts average comments: 6.53\n",
      "All posts average points: 15.03\n",
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n",
      "['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']\n",
      "['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']\n",
      "\n",
      "\n",
      "The highest number of comments an individual post received: \n",
      "\n",
      "['11814828', 'Ask HN: Who is hiring? (June 2016)', '', '644', '1007', 'whoishiring', '6/1/2016 15:01']\n",
      "['11667494', 'Show HN: BitKeeper  Enterprise-ready version control, now open-source', 'https://www.bitkeeper.org/', '384', '306', 'wscott', '5/10/2016 14:39']\n",
      "['11966167', 'UK votes to leave EU', 'http://www.bbc.co.uk/news/uk-politics-36615028', '3125', '2531', 'dmmalam', '6/24/2016 3:48']\n",
      "['11966167', 'UK votes to leave EU', 'http://www.bbc.co.uk/news/uk-politics-36615028', '3125', '2531', 'dmmalam', '6/24/2016 3:48']\n",
      "\n",
      "\n",
      "The highest number of comments an individual post received: \n",
      "\n",
      "['11814828', 'Ask HN: Who is hiring? (June 2016)', '', '644', '1007', 'whoishiring', '6/1/2016 15:01']\n",
      "['11667494', 'Show HN: BitKeeper  Enterprise-ready version control, now open-source', 'https://www.bitkeeper.org/', '384', '306', 'wscott', '5/10/2016 14:39']\n",
      "['11966167', 'UK votes to leave EU', 'http://www.bbc.co.uk/news/uk-politics-36615028', '3125', '2531', 'dmmalam', '6/24/2016 3:48']\n",
      "['11966167', 'UK votes to leave EU', 'http://www.bbc.co.uk/news/uk-politics-36615028', '3125', '2531', 'dmmalam', '6/24/2016 3:48']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## post stats excluding no-engagement posts\n",
    "string_format2 = \"In the scraped data, excluding posts without direct engagement, there are {ask:,} \\\"Ask HN\\\" posts, {show:,} \\\"Show HN\\\" posts, {otter:,} \\\"other posts\\\", and a total of {totes:,} posts.\"\n",
    "string_output2 = string_format2.format(ask=len(ask_comments), show=len(show_comments), otter=len(other_comments), totes=len(hn_comments))\n",
    "print(string_output2, '\\n')\n",
    "\n",
    "print('\\n')\n",
    "print(\"An overview of posts, excluding posts without direct engagement:\")\n",
    "print(\"Ask HN posts: {aposts:,}\".format(aposts=len(ask_comments)))\n",
    "print(\"Ask HN average comments: {avg:.2f}\".format(avg=avg_ask_comments))\n",
    "print(\"Ask HN average points: {:.2f}\".format(average_calc(ask_comments, 3)))\n",
    "for row in ask_comments[:5]:\n",
    "    print(row)\n",
    "print('\\n')\n",
    "print(\"Show HN posts: {aposts:,}\".format(aposts=len(show_comments)))\n",
    "print(\"Show HN average comments: {avg:.2f}\".format(avg=avg_show_comments))\n",
    "print(\"Show HN average points: {:.2f}\".format(average_calc(show_comments, 3)))\n",
    "for row in show_comments[:5]:\n",
    "    print(row)\n",
    "print('\\n')\n",
    "print(\"Other posts: {aposts:,}\".format(aposts=len(other_comments)))\n",
    "print(\"Other average comments: {avg:.2f}\".format(avg=avg_other_comments))\n",
    "print(\"Other posts average points: {:.2f}\".format(average_calc(other_comments, 3)))\n",
    "for row in other_comments[:5]:\n",
    "    print(row)\n",
    "print('\\n')\n",
    "print(\"All posts: {aposts:,}\".format(aposts=len(hn_comments)))\n",
    "print(\"All posts average comments: {avg:.2f}\".format(avg=hn_avg_comments))\n",
    "print(\"All posts average points: {:.2f}\".format(average_calc(hn_comments, 3)))\n",
    "for row in hn_comments[:5]:\n",
    "    print(row)\n",
    "    \n",
    "## post stats including no engagement\n",
    "string_format = \"In the scraped data, including posts with no direct engagement, there are {ask:,} \\\"Ask HN\\\" posts, {show:,} \\\"Show HN\\\" posts, {otter:,} \\\"other posts\\\", and a total of {totes:,} posts.\"\n",
    "string_output = string_format.format(ask=len(ask_posts), show=len(show_posts), otter=len(other_posts), totes=len(hn))\n",
    "print(string_output, '\\n')\n",
    "print(\"An overview of posts, including posts without direct engagement:\")\n",
    "print(\"Ask HN posts: {aposts:,}\".format(aposts=len(ask_posts)))\n",
    "print(\"Ask HN average comments: {avg:.2f}\".format(avg=avg_ask_posts))\n",
    "print(\"Ask HN average points: {:.2f}\".format(average_calc(ask_posts, 3)))\n",
    "for row in ask_posts[:5]:\n",
    "    print(row)\n",
    "print('\\n')\n",
    "print(\"Show HN posts: {aposts:,}\".format(aposts=len(show_posts)))\n",
    "print(\"Show HN average comments: {avg:.2f}\".format(avg=avg_show_posts))\n",
    "print(\"Show HN average points: {:.2f}\".format(average_calc(show_posts, 3)))\n",
    "for row in show_posts[:5]:\n",
    "    print(row)\n",
    "print('\\n')\n",
    "print(\"Other posts: {aposts:,}\".format(aposts=len(other_posts)))\n",
    "print(\"Other average comments: {avg:.2f}\".format(avg=avg_other_posts))\n",
    "print(\"Other posts average points: {:.2f}\".format(average_calc(other_posts, 3)))\n",
    "for row in show_posts[:5]:\n",
    "    print(row)\n",
    "print('\\n')\n",
    "print(\"All posts: {aposts:,}\".format(aposts=len(hn)))\n",
    "print(\"All posts average comments: {avg:.2f}\".format(avg=avg_all))\n",
    "print(\"All posts average points: {:.2f}\".format(average_calc(hn, 3)))\n",
    "for row in hn[:5]:\n",
    "    print(row)\n",
    "print('\\n')\n",
    "\n",
    "## Max comments of post types\n",
    "# ['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
    "max_comments = [max(ask_posts, key=lambda x: float(x[4])), max(show_posts, key=lambda x: float(x[4])), max(other_posts, key=lambda x: float(x[4])), max(hn, key=lambda x: float(x[4]))]\n",
    "print(\"The highest number of comments an individual post received:\", '\\n')\n",
    "for row in max_comments:\n",
    "    print(row)\n",
    "print('\\n')\n",
    "## Max points of post types\n",
    "# ['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
    "max_points = [max(ask_posts, key=lambda x: float(x[3])), max(show_posts, key=lambda x: float(x[3])), max(other_posts, key=lambda x: float(x[3])), max(hn, key=lambda x: float(x[3]))]\n",
    "print(\"The highest number of comments an individual post received:\", '\\n')\n",
    "for row in max_comments:\n",
    "    print(row)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610dcb2d",
   "metadata": {},
   "source": [
    "## Calculating average comments and points per hour\n",
    "\n",
    "Below is a function used to calculate the comments and points per hour for a given list. This was used to generate the timetables that illustrate the average highest hours of engagement for commenting and up/downvoting on Hacker News.\n",
    "\n",
    "The code block below that is also used to produce easy-to-read output. That was also used for the analyses above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc027bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate freq tables for posts per hour and comments/points per hour\n",
    "# use freq tables to calc avg comments/points per hour\n",
    "import datetime as dt\n",
    "def hourly_comments(dataset, index_comments):\n",
    "    results = []\n",
    "    #loop over dataset, append to list of lists\n",
    "    for t in dataset:\n",
    "        results.append([t[6], int(t[index_comments])])\n",
    "    counts_by_hour = {}\n",
    "    comments_by_hour = {}\n",
    "    # loop over new list of lists, populate dictionary, parse string for datetime\n",
    "    for x in results:\n",
    "        x[0] = dt.datetime.strptime(x[0], \"%m/%d/%Y %H:%M\")\n",
    "        hour = x[0].hour\n",
    "        if hour in counts_by_hour:\n",
    "            counts_by_hour[hour] += 1\n",
    "            comments_by_hour[hour] += x[1]\n",
    "        else:\n",
    "            counts_by_hour[hour] = 1\n",
    "            comments_by_hour[hour] = x[1]\n",
    "    avg_by_hour = []\n",
    "    # populate list of lists while calcing an average and appending it to aforementioned list\n",
    "    for i in counts_by_hour:\n",
    "        avg_by_hour.append([comments_by_hour[i]/counts_by_hour[i],i])\n",
    "    #sorts list of lists by hour is descending order\n",
    "    sorted_avg = sorted(avg_by_hour, reverse=True)\n",
    "    return sorted_avg\n",
    "\n",
    "## exclusion of zero-comment submissions\n",
    "## calc the average comments during a given hour in the day\n",
    "# ask posts\n",
    "ex_hourly_ask = hourly_comments(ask_comments, 4)\n",
    "# show posts\n",
    "ex_hourly_show = hourly_comments(show_comments, 4)\n",
    "# other posts\n",
    "ex_hourly_other = hourly_comments(other_comments, 4)\n",
    "# all posts\n",
    "ex_hourly_hn_comments = hourly_comments(hn_comments, 4)\n",
    "## inclusion of zero-comment submissions\n",
    "## calc the average comments during a given hour in the day\n",
    "# ask posts\n",
    "in_hourly_ask = hourly_comments(ask_posts, 4)\n",
    "# show posts\n",
    "in_hourly_show = hourly_comments(show_posts, 4)\n",
    "# other posts\n",
    "in_hourly_other = hourly_comments(other_posts, 4)\n",
    "# all posts\n",
    "in_hourly_hn = hourly_comments(hn, 4)\n",
    "\n",
    "##using hourly comments function to calc avg pts per hour\n",
    "## exclusion of zero-comment submissions\n",
    "# ask posts\n",
    "ex_points_ask = hourly_comments(ask_comments, 3)\n",
    "# show posts\n",
    "ex_points_show = hourly_comments(show_comments, 3)\n",
    "# other posts\n",
    "ex_points_other = hourly_comments(other_comments, 3)\n",
    "# all posts\n",
    "ex_points_hn_comments = hourly_comments(hn_comments, 3)\n",
    "## inclusion of zero-comment submissions\n",
    "## calc the average comments during a given hour in the day\n",
    "# ask posts\n",
    "in_points_ask = hourly_comments(ask_posts, 3)\n",
    "# show posts\n",
    "in_points_show = hourly_comments(show_posts, 3)\n",
    "# other posts\n",
    "in_points_other = hourly_comments(other_posts, 3)\n",
    "# all posts\n",
    "in_points_hn = hourly_comments(hn, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4c403b72",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An overview of average, high-engagement hours for posts, excluding zero-comment submissions. \n",
      "\n",
      "Ask HN: Hours of the average highest engagement\n",
      "15:00: 39.67 average comments per post.\n",
      "13:00: 22.22 average comments per post.\n",
      "12:00: 15.45 average comments per post.\n",
      "10:00: 13.76 average comments per post.\n",
      "17:00: 13.73 average comments per post.\n",
      "\n",
      "\n",
      "Show HN: Hours of the average highest engagement\n",
      "07:00: 12.42 average comments per post.\n",
      "12:00: 12.03 average comments per post.\n",
      "14:00: 11.60 average comments per post.\n",
      "08:00: 11.07 average comments per post.\n",
      "04:00: 10.87 average comments per post.\n",
      "\n",
      "\n",
      "Other posts: Hours of the average highest engagement\n",
      "13:00: 29.37 average comments per post.\n",
      "12:00: 29.20 average comments per post.\n",
      "14:00: 28.09 average comments per post.\n",
      "15:00: 27.97 average comments per post.\n",
      "11:00: 27.13 average comments per post.\n",
      "\n",
      "\n",
      "All HN: Hours of the average highest engagement\n",
      "15:00: 27.63 average comments per post.\n",
      "13:00: 27.31 average comments per post.\n",
      "12:00: 26.76 average comments per post.\n",
      "14:00: 25.66 average comments per post.\n",
      "11:00: 24.62 average comments per post.\n",
      "\n",
      "\n",
      "An overview of the average highest points for a post, excluding zero-comment submissions. \n",
      "\n",
      "Ask HN: hours of the highest engagement vis-a-vis up/downvotes\n",
      "15:00: 29.31 average points per post.\n",
      "13:00: 23.77 average points per post.\n",
      "17:00: 16.96 average points per post.\n",
      "10:00: 16.71 average points per post.\n",
      "12:00: 16.53 average points per post.\n",
      "\n",
      "\n",
      "Show HN: hours of the highest engagement vis-a-vis up/downvotes\n",
      "12:00: 33.57 average points per post.\n",
      "11:00: 31.57 average points per post.\n",
      "23:00: 30.40 average points per post.\n",
      "19:00: 29.80 average points per post.\n",
      "06:00: 29.38 average points per post.\n",
      "\n",
      "\n",
      "Other posts: hours of the highest engagement vis-a-vis up/downvotes\n",
      "13:00: 58.62 average points per post.\n",
      "12:00: 57.53 average points per post.\n",
      "15:00: 55.95 average points per post.\n",
      "17:00: 55.64 average points per post.\n",
      "16:00: 55.62 average points per post.\n",
      "\n",
      "\n",
      "All HN: hours of the highest engagement vis-a-vis up/downvotes\n",
      "13:00: 53.61 average points per post.\n",
      "12:00: 52.49 average points per post.\n",
      "15:00: 51.11 average points per post.\n",
      "17:00: 50.46 average points per post.\n",
      "16:00: 50.00 average points per post.\n",
      "\n",
      "\n",
      "An overview of average, high-engagement hours for posts, including zero-comment submissions. \n",
      "\n",
      "Ask HN: Hours of the average highest engagement\n",
      "15:00: 28.68 average comments per post.\n",
      "13:00: 16.32 average comments per post.\n",
      "12:00: 12.38 average comments per post.\n",
      "02:00: 11.14 average comments per post.\n",
      "10:00: 10.68 average comments per post.\n",
      "\n",
      "\n",
      "Show HN: Hours of the average highest engagement\n",
      "12:00: 6.99 average comments per post.\n",
      "07:00: 6.68 average comments per post.\n",
      "11:00: 6.00 average comments per post.\n",
      "08:00: 5.60 average comments per post.\n",
      "14:00: 5.52 average comments per post.\n",
      "\n",
      "\n",
      "Other posts: Hours of the average highest engagement\n",
      "12:00: 7.59 average comments per post.\n",
      "11:00: 7.37 average comments per post.\n",
      "02:00: 7.18 average comments per post.\n",
      "13:00: 7.15 average comments per post.\n",
      "05:00: 6.79 average comments per post.\n",
      "\n",
      "\n",
      "All HN: Hours of the average highest engagement\n",
      "12:00: 7.69 average comments per post.\n",
      "11:00: 7.37 average comments per post.\n",
      "13:00: 7.34 average comments per post.\n",
      "02:00: 7.27 average comments per post.\n",
      "15:00: 7.05 average comments per post.\n",
      "\n",
      "\n",
      "An overview of the average highest points for a post, including zero-comment submissions. \n",
      "\n",
      "Ask HN: hours of the highest engagement vis-a-vis up/downvotes\n",
      "15:00: 21.64 average points per post.\n",
      "13:00: 17.93 average points per post.\n",
      "12:00: 13.58 average points per post.\n",
      "10:00: 13.44 average points per post.\n",
      "17:00: 12.19 average points per post.\n",
      "\n",
      "\n",
      "Show HN: hours of the highest engagement vis-a-vis up/downvotes\n",
      "12:00: 20.91 average points per post.\n",
      "11:00: 19.26 average points per post.\n",
      "13:00: 17.02 average points per post.\n",
      "19:00: 16.06 average points per post.\n",
      "06:00: 15.99 average points per post.\n",
      "\n",
      "\n",
      "Other posts: hours of the highest engagement vis-a-vis up/downvotes\n",
      "02:00: 16.71 average points per post.\n",
      "12:00: 16.70 average points per post.\n",
      "11:00: 16.29 average points per post.\n",
      "00:00: 16.12 average points per post.\n",
      "13:00: 16.02 average points per post.\n",
      "\n",
      "\n",
      "All HN: hours of the highest engagement vis-a-vis up/downvotes\n",
      "12:00: 16.79 average points per post.\n",
      "02:00: 16.41 average points per post.\n",
      "11:00: 16.19 average points per post.\n",
      "13:00: 16.11 average points per post.\n",
      "00:00: 15.88 average points per post.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## posts excluding zero-comment submissions, comments\n",
    "print(\"An overview of average, high-engagement hours for posts, excluding zero-comment submissions.\", '\\n')\n",
    "print(\"Ask HN: Hours of the average highest engagement\")\n",
    "for item in ex_hourly_ask[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {comments:.2f} average comments per post.\".format(hour=item[1], comments=item[0])\n",
    "    print(strang)\n",
    "print('\\n')    \n",
    "print(\"Show HN: Hours of the average highest engagement\")\n",
    "for item in ex_hourly_show[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {comments:.2f} average comments per post.\".format(hour=item[1], comments=item[0])\n",
    "    print(strang)\n",
    "print('\\n')    \n",
    "print(\"Other posts: Hours of the average highest engagement\")\n",
    "for item in ex_hourly_other[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {comments:.2f} average comments per post.\".format(hour=item[1], comments=item[0])\n",
    "    print(strang)\n",
    "print('\\n')    \n",
    "print(\"All HN: Hours of the average highest engagement\")\n",
    "for item in ex_hourly_hn_comments[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {comments:.2f} average comments per post.\".format(hour=item[1], comments=item[0])\n",
    "    print(strang)\n",
    "print('\\n')\n",
    "\n",
    "# posts excluding zero-comment submissions, points\n",
    "print(\"An overview of the average highest points for a post, excluding zero-comment submissions.\", '\\n')\n",
    "print(\"Ask HN: hours of the highest engagement vis-a-vis up/downvotes\")\n",
    "for item in ex_points_ask[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {points:.2f} average points per post.\".format(hour=item[1], points=item[0])\n",
    "    print(strang)\n",
    "print('\\n')\n",
    "print(\"Show HN: hours of the highest engagement vis-a-vis up/downvotes\")\n",
    "for item in ex_points_show[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {points:.2f} average points per post.\".format(hour=item[1], points=item[0])\n",
    "    print(strang)\n",
    "print('\\n')\n",
    "print(\"Other posts: hours of the highest engagement vis-a-vis up/downvotes\")\n",
    "for item in ex_points_other[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {points:.2f} average points per post.\".format(hour=item[1], points=item[0])\n",
    "    print(strang)\n",
    "print('\\n')\n",
    "print(\"All HN: hours of the highest engagement vis-a-vis up/downvotes\")\n",
    "for item in ex_points_hn_comments[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {points:.2f} average points per post.\".format(hour=item[1], points=item[0])\n",
    "    print(strang)\n",
    "print('\\n')\n",
    "\n",
    "# posts including zero-comment submissions, comments\n",
    "print(\"An overview of average, high-engagement hours for posts, including zero-comment submissions.\", '\\n')\n",
    "print(\"Ask HN: Hours of the average highest engagement\")\n",
    "for item in in_hourly_ask[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {comments:.2f} average comments per post.\".format(hour=item[1], comments=item[0])\n",
    "    print(strang)\n",
    "print('\\n')    \n",
    "print(\"Show HN: Hours of the average highest engagement\")\n",
    "for item in in_hourly_show[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {comments:.2f} average comments per post.\".format(hour=item[1], comments=item[0])\n",
    "    print(strang)\n",
    "print('\\n')    \n",
    "print(\"Other posts: Hours of the average highest engagement\")\n",
    "for item in in_hourly_other[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {comments:.2f} average comments per post.\".format(hour=item[1], comments=item[0])\n",
    "    print(strang)\n",
    "print('\\n')    \n",
    "print(\"All HN: Hours of the average highest engagement\")\n",
    "for item in in_hourly_hn[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {comments:.2f} average comments per post.\".format(hour=item[1], comments=item[0])\n",
    "    print(strang)\n",
    "print('\\n')\n",
    "\n",
    "#posts including zero-comment submission, points\n",
    "print(\"An overview of the average highest points for a post, including zero-comment submissions.\", '\\n')\n",
    "print(\"Ask HN: hours of the highest engagement vis-a-vis up/downvotes\")\n",
    "for item in in_points_ask[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {points:.2f} average points per post.\".format(hour=item[1], points=item[0])\n",
    "    print(strang)\n",
    "print('\\n')\n",
    "print(\"Show HN: hours of the highest engagement vis-a-vis up/downvotes\")\n",
    "for item in in_points_show[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {points:.2f} average points per post.\".format(hour=item[1], points=item[0])\n",
    "    print(strang)\n",
    "print('\\n')\n",
    "print(\"Other posts: hours of the highest engagement vis-a-vis up/downvotes\")\n",
    "for item in in_points_other[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {points:.2f} average points per post.\".format(hour=item[1], points=item[0])\n",
    "    print(strang)\n",
    "print('\\n')\n",
    "print(\"All HN: hours of the highest engagement vis-a-vis up/downvotes\")\n",
    "for item in in_points_hn[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {points:.2f} average points per post.\".format(hour=item[1], points=item[0])\n",
    "    print(strang)\n",
    "print('\\n')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
