{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b25ef85b",
   "metadata": {},
   "source": [
    "# A brief look at Hacker News engagement\n",
    "## Hacker News can be found here: https://news.ycombinator.com/\n",
    "\n",
    "This will be a brief look at how engagement compares among Ask HN, Show HN, and other posts. This brief will also examaine how, or if, time of day impacts engagement.\n",
    "\n",
    "Hacker News enables users to post and share content to the platform. Users can upvote and downvote submissions, resulting in a point count. It is similar to Reddit. Engagement in this context means users (a) commented on posts and (b) the points a post received. \n",
    "\n",
    "Ask HN posts are a format in which users submit questions for the community to answer.\n",
    "\n",
    "Answers sought:\n",
    "* Do Ask HN or Show HN posts recieve more comments on average?\n",
    "* Do posts created at a certain time recieve more comments on average?\n",
    "\n",
    "This analysis will be done in two parts:\n",
    "* Exclusion of zero-comment posts, ie posts with low to no engagement.\n",
    "* Inclusion of zero-comment posts, ie posts with low to no engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cb586256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining functions for exploration\n",
    "\n",
    "# open a csv file\n",
    "## a function to open datasets\n",
    "## returns the data set and header row or just returns the data set as a list of lists\n",
    "## recommended manner to call function:\n",
    "## variable_data, header_data = open_dataset('filename')\n",
    "def open_dataset(file_name, has_head=True):\n",
    "    opened_file = open(file_name)\n",
    "    from csv import reader\n",
    "    read_file = reader(opened_file)\n",
    "    data = list(read_file)\n",
    "    if has_head:\n",
    "        return data[1:], data[0]\n",
    "    else:\n",
    "        return data\n",
    "\n",
    "# explores a dataset\n",
    "def explore_data(dataset, start, end, rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row, '\\n')\n",
    "    if rows_and_columns:\n",
    "        print('Number of rows:', len(dataset))\n",
    "        print('Number of columns:', len(dataset[0]))\n",
    "        \n",
    "# checks for shifted columns in a dataset\n",
    "# see https://community.dataquest.io/t/guided-project-finding-insights-about-popular-hacker-news-posts/557800\n",
    "def check_shifted(header, dataset):\n",
    "    header_len = len(header)\n",
    "    error_count = 0\n",
    "    for row in dataset:\n",
    "        if len(row) != header_len:\n",
    "            error_count += 1\n",
    "            print(header, '\\n')\n",
    "            print('Row Index: ', dataset.index(row), '\\n')\n",
    "            print(row, '/n')\n",
    "    print('Column Shift Errors: ', error_count)\n",
    "\n",
    "# checks for null or missing data\n",
    "# see https://community.dataquest.io/t/guided-project-finding-insights-about-popular-hacker-news-posts/557800\n",
    "def check_null_data(dataset_header, dataset, index):\n",
    "    null_value = False\n",
    "    null_count = 0\n",
    "    # Loop over each row in the dataset to identify any missing values at the given index\n",
    "    \n",
    "    for row in dataset:\n",
    "        if row[index] == '':\n",
    "            null_value = True\n",
    "            null_count += 1\n",
    "        if null_value == True:\n",
    "            print(dataset_header, '\\n')\n",
    "            print('Row Index: ', dataset.index(row), '\\n') # Print the row number where the error was found\n",
    "            print(row, '\\n')\n",
    "            null_value = False\n",
    "    # Print the number of missing values identified at the given index\n",
    "    print('Missing \"{}\" Values Identified: {}'.format(hn_header[index], null_count)) #uses object defined outside of function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216e0bbc",
   "metadata": {},
   "source": [
    "#### below is an excerpt from the dataset\n",
    "\n",
    "For a brief overview of what we have to work with, I have printed the header information and five rows of information from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "62de4b75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'] \n",
      "\n",
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26'] \n",
      "\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24'] \n",
      "\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19'] \n",
      "\n",
      "['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16'] \n",
      "\n",
      "['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14'] \n",
      "\n",
      "Number of rows: 293119\n",
      "Number of columns: 7\n",
      "\n",
      "\n",
      "Column Shift Errors:  0\n",
      "\n",
      "\n",
      "Missing \"num_points\" Values Identified: 0\n",
      "Missing \"num_comments\" Values Identified: 0\n",
      "Missing \"created_at\" Values Identified: 0\n"
     ]
    }
   ],
   "source": [
    "#using the open_dataset function\n",
    "hn, hn_header = open_dataset(file_name='HN_posts_year_to_Sep_26_2016.csv')\n",
    "\n",
    "print(hn_header, '\\n')\n",
    "explore_data(hn, 0, 5, True)\n",
    "print('\\n')\n",
    "check_shifted(hn_header, hn)\n",
    "print('\\n')\n",
    "# ['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
    "check_null_data(hn_header, hn, 3)\n",
    "check_null_data(hn_header, hn, 4)\n",
    "check_null_data(hn_header, hn, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "deaa4ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pt 2\n",
    "# removing header\n",
    "# completed during import\n",
    "# pt 3\n",
    "# filtering the data\n",
    "# four lists to separate ask, show, others, and all posts\n",
    "# 'other' posts consist of all non-ask and show posts.\n",
    "\n",
    "# collects posts with comments\n",
    "def commented_posts(dataset, index):\n",
    "    output = []\n",
    "    for row in dataset:\n",
    "        num_comments = int(row[index])\n",
    "        if num_comments != 0:\n",
    "            output.append(row)\n",
    "    return output\n",
    "\n",
    "#calc avg\n",
    "def average_calc(dataset, index):\n",
    "    total = 0\n",
    "    for item in dataset:\n",
    "        total += int(item[index])    \n",
    "    return total / len(dataset)\n",
    "\n",
    "# collect user submissions by title\n",
    "def collect_titles(dataset, index):\n",
    "    ask_posts = []\n",
    "    show_posts = []\n",
    "    other_posts = []\n",
    "    for row in dataset:\n",
    "        title = row[index]\n",
    "        title = title.lower()\n",
    "        if title.startswith('ask hn'):\n",
    "            ask_posts.append(row)\n",
    "        elif title.startswith('show hn'):\n",
    "            show_posts.append(row)\n",
    "        else:\n",
    "            other_posts.append(row)\n",
    "    return ask_posts, show_posts, other_posts\n",
    "    \n",
    "collect_titles(hn, 1) # collects posts into three list obj that \n",
    "#includes all posts, including those without engagement\n",
    "\n",
    "## excludes posts without comments/engagement\n",
    "ask_comments = commented_posts(ask_posts, 4)\n",
    "show_comments = commented_posts(show_posts, 4)\n",
    "other_comments = commented_posts(other_posts, 4)\n",
    "hn_comments = commented_posts(hn, 4) # all posts with engagement\n",
    "# avg comments check\n",
    "avg_ask_comments = average_calc(ask_comments, 4)\n",
    "avg_show_comments = average_calc(show_comments, 4)\n",
    "avg_other_comments = average_calc(other_comments, 4)\n",
    "hn_avg_comments = average_calc(hn_comments, 4) # avg comments of all posts with engagement\n",
    "\n",
    "## includes posts without engagement\n",
    "# average number of comments check\n",
    "avg_ask_posts = average_calc(ask_posts, 4)\n",
    "avg_show_posts = average_calc(show_posts, 4)\n",
    "avg_other_posts = average_calc(other_posts, 4)\n",
    "avg_all = average_calc(hn, 4) # avg comments of all posts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "49a89f82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the scraped data, excluding posts without direct engagement, there are 6,911 \"Ask HN\" posts, 5,059 \"Show HN\" posts, 68,431 \"other posts\", and a total of 80,401 posts. \n",
      "\n",
      "\n",
      "\n",
      "An overview of posts, excluding posts without direct engagement:\n",
      "Ask HN posts: 6,911\n",
      "Ask HN average comments: 13.74\n",
      "Ask HN average points: 14.40\n",
      "['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53']\n",
      "['12578522', 'Ask HN: How do you pass on your work when you die?', '', '6', '3', 'PascLeRasc', '9/26/2016 1:17']\n",
      "['12577870', 'Ask HN: Why join a fund when you can be an angel?', '', '1', '3', 'anthony_james', '9/25/2016 22:48']\n",
      "['12577647', 'Ask HN: Someone uses stock trading as passive income?', '', '5', '2', '00taffe', '9/25/2016 21:50']\n",
      "['12576946', 'Ask HN: How hard would it be to make a cheap, hackable phone?', '', '2', '1', 'hkt', '9/25/2016 19:30']\n",
      "\n",
      "\n",
      "Show HN posts: 5,059\n",
      "Show HN average comments: 9.81\n",
      "Show HN average points: 26.62\n",
      "['12577142', 'Show HN: Jumble  Essays on the go #PaulInYourPocket', 'https://itunes.apple.com/us/app/jumble-find-startup-essay/id1150939197?ls=1&mt=8', '1', '1', 'ryderj', '9/25/2016 20:06']\n",
      "['12576813', 'Show HN: Learn Japanese Vocab via multiple choice questions', 'http://japanese.vul.io/', '1', '1', 'soulchild37', '9/25/2016 19:06']\n",
      "['12576090', 'Show HN: Markov chain Twitter bot. Trained on comments left on Pornhub', 'https://twitter.com/botsonasty', '3', '1', 'keepingscore', '9/25/2016 16:50']\n",
      "['12575471', 'Show HN: Project-Okot: Novel, CODE-FREE data-apps in mere seconds', 'https://studio.nuchwezi.com/', '3', '1', 'nfixx', '9/25/2016 14:30']\n",
      "['12574773', 'Show HN: Cursor that Screenshot', 'http://edward.codes/cursor-that-screenshot', '3', '3', 'ed-bit', '9/25/2016 10:50']\n",
      "\n",
      "\n",
      "Other posts: 68,431\n",
      "Other average comments: 25.84\n",
      "Other posts average points: 53.43\n",
      "['12578975', 'Saving the Hassle of Shopping', 'https://blog.menswr.com/2016/09/07/whats-new-with-your-style-feed/', '1', '1', 'bdoux', '9/26/2016 3:13']\n",
      "['12578822', 'Amazons Algorithms Dont Find You the Best Deals', 'https://www.technologyreview.com/s/602442/amazons-algorithms-dont-find-you-the-best-deals/', '1', '1', 'yarapavan', '9/26/2016 2:26']\n",
      "['12578694', 'Emergency dose of epinephrine that does not cost an arm and a leg', 'http://m.imgur.com/gallery/th6Ua', '2', '1', 'dredmorbius', '9/26/2016 1:54']\n",
      "['12578624', 'Phone Makers Could Cut Off Drivers. So Why Dont They?', 'http://www.nytimes.com/2016/09/25/technology/phone-makers-could-cut-off-drivers-so-why-dont-they.html', '4', '1', 'danso', '9/26/2016 1:37']\n",
      "['12578556', 'OpenMW, Open Source Elderscrolls III: Morrowind Reimplementation', 'https://openmw.org/en/', '32', '3', 'rocky1138', '9/26/2016 1:24']\n",
      "\n",
      "\n",
      "All posts: 80,401\n",
      "All posts average comments: 23.79\n",
      "All posts average points: 48.39\n",
      "['12578975', 'Saving the Hassle of Shopping', 'https://blog.menswr.com/2016/09/07/whats-new-with-your-style-feed/', '1', '1', 'bdoux', '9/26/2016 3:13']\n",
      "['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53']\n",
      "['12578822', 'Amazons Algorithms Dont Find You the Best Deals', 'https://www.technologyreview.com/s/602442/amazons-algorithms-dont-find-you-the-best-deals/', '1', '1', 'yarapavan', '9/26/2016 2:26']\n",
      "['12578694', 'Emergency dose of epinephrine that does not cost an arm and a leg', 'http://m.imgur.com/gallery/th6Ua', '2', '1', 'dredmorbius', '9/26/2016 1:54']\n",
      "['12578624', 'Phone Makers Could Cut Off Drivers. So Why Dont They?', 'http://www.nytimes.com/2016/09/25/technology/phone-makers-could-cut-off-drivers-so-why-dont-they.html', '4', '1', 'danso', '9/26/2016 1:37']\n",
      "In the scraped data, including posts with no direct engagement, there are 9,139 \"Ask HN\" posts, 10,158 \"Show HN\" posts, 273,822 \"other posts\", and a total of 293,119 posts. \n",
      "\n",
      "An overview of posts, including posts without direct engagement:\n",
      "Ask HN posts: 9,139\n",
      "Ask HN average comments: 10.39\n",
      "Ask HN average points: 11.31\n",
      "['12578908', 'Ask HN: What TLD do you use for local development?', '', '4', '7', 'Sevrene', '9/26/2016 2:53']\n",
      "['12578522', 'Ask HN: How do you pass on your work when you die?', '', '6', '3', 'PascLeRasc', '9/26/2016 1:17']\n",
      "['12577908', 'Ask HN: How a DNS problem can be limited to a geographic region?', '', '1', '0', 'kuon', '9/25/2016 22:57']\n",
      "['12577870', 'Ask HN: Why join a fund when you can be an angel?', '', '1', '3', 'anthony_james', '9/25/2016 22:48']\n",
      "['12577647', 'Ask HN: Someone uses stock trading as passive income?', '', '5', '2', '00taffe', '9/25/2016 21:50']\n",
      "\n",
      "\n",
      "Show HN posts: 10,158\n",
      "Show HN average comments: 4.89\n",
      "Show HN average points: 14.84\n",
      "['12578335', 'Show HN: Finding puns computationally', 'http://puns.samueltaylor.org/', '2', '0', 'saamm', '9/26/2016 0:36']\n",
      "['12578182', 'Show HN: A simple library for complicated animations', 'https://christinecha.github.io/choreographer-js/', '1', '0', 'christinecha', '9/26/2016 0:01']\n",
      "['12578098', 'Show HN: WebGL visualization of DNA sequences', 'http://grondilu.github.io/dna.html', '1', '0', 'grondilu', '9/25/2016 23:44']\n",
      "['12577991', 'Show HN: Pomodoro-centric, heirarchical project management with ES6 modules', 'https://github.com/jakebian/zeal', '2', '0', 'dbranes', '9/25/2016 23:17']\n",
      "['12577142', 'Show HN: Jumble  Essays on the go #PaulInYourPocket', 'https://itunes.apple.com/us/app/jumble-find-startup-essay/id1150939197?ls=1&mt=8', '1', '1', 'ryderj', '9/25/2016 20:06']\n",
      "\n",
      "\n",
      "Other posts: 273,822\n",
      "Other average comments: 6.46\n",
      "Other posts average points: 15.16\n",
      "['12578335', 'Show HN: Finding puns computationally', 'http://puns.samueltaylor.org/', '2', '0', 'saamm', '9/26/2016 0:36']\n",
      "['12578182', 'Show HN: A simple library for complicated animations', 'https://christinecha.github.io/choreographer-js/', '1', '0', 'christinecha', '9/26/2016 0:01']\n",
      "['12578098', 'Show HN: WebGL visualization of DNA sequences', 'http://grondilu.github.io/dna.html', '1', '0', 'grondilu', '9/25/2016 23:44']\n",
      "['12577991', 'Show HN: Pomodoro-centric, heirarchical project management with ES6 modules', 'https://github.com/jakebian/zeal', '2', '0', 'dbranes', '9/25/2016 23:17']\n",
      "['12577142', 'Show HN: Jumble  Essays on the go #PaulInYourPocket', 'https://itunes.apple.com/us/app/jumble-find-startup-essay/id1150939197?ls=1&mt=8', '1', '1', 'ryderj', '9/25/2016 20:06']\n",
      "\n",
      "\n",
      "All posts: 293,119\n",
      "All posts average comments: 6.53\n",
      "All posts average points: 15.03\n",
      "['12579008', 'You have two days to comment if you want stem cells to be classified as your own', 'http://www.regulations.gov/document?D=FDA-2015-D-3719-0018', '1', '0', 'altstar', '9/26/2016 3:26']\n",
      "['12579005', 'SQLAR  the SQLite Archiver', 'https://www.sqlite.org/sqlar/doc/trunk/README.md', '1', '0', 'blacksqr', '9/26/2016 3:24']\n",
      "['12578997', 'What if we just printed a flatscreen television on the side of our boxes?', 'https://medium.com/vanmoof/our-secrets-out-f21c1f03fdc8#.ietxmez43', '1', '0', 'pavel_lishin', '9/26/2016 3:19']\n",
      "['12578989', 'algorithmic music', 'http://cacm.acm.org/magazines/2011/7/109891-algorithmic-composition/fulltext', '1', '0', 'poindontcare', '9/26/2016 3:16']\n",
      "['12578979', 'How the Data Vault Enables the Next-Gen Data Warehouse and Data Lake', 'https://www.talend.com/blog/2016/05/12/talend-and-Â\\x93the-data-vaultÂ\\x94', '1', '0', 'markgainor1', '9/26/2016 3:14']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## post stats excluding no-engagement posts\n",
    "string_format2 = \"In the scraped data, excluding posts without direct engagement, there are {ask:,} \\\"Ask HN\\\" posts, {show:,} \\\"Show HN\\\" posts, {otter:,} \\\"other posts\\\", and a total of {totes:,} posts.\"\n",
    "string_output2 = string_format2.format(ask=len(ask_comments), show=len(show_comments), otter=len(other_comments), totes=len(hn_comments))\n",
    "print(string_output2, '\\n')\n",
    "\n",
    "print('\\n')\n",
    "print(\"An overview of posts, excluding posts without direct engagement:\")\n",
    "print(\"Ask HN posts: {aposts:,}\".format(aposts=len(ask_comments)))\n",
    "print(\"Ask HN average comments: {avg:.2f}\".format(avg=avg_ask_comments))\n",
    "print(\"Ask HN average points: {:.2f}\".format(average_calc(ask_comments, 3)))\n",
    "for row in ask_comments[:5]:\n",
    "    print(row)\n",
    "print('\\n')\n",
    "print(\"Show HN posts: {aposts:,}\".format(aposts=len(show_comments)))\n",
    "print(\"Show HN average comments: {avg:.2f}\".format(avg=avg_show_comments))\n",
    "print(\"Show HN average points: {:.2f}\".format(average_calc(show_comments, 3)))\n",
    "for row in show_comments[:5]:\n",
    "    print(row)\n",
    "print('\\n')\n",
    "print(\"Other posts: {aposts:,}\".format(aposts=len(other_comments)))\n",
    "print(\"Other average comments: {avg:.2f}\".format(avg=avg_other_comments))\n",
    "print(\"Other posts average points: {:.2f}\".format(average_calc(other_comments, 3)))\n",
    "for row in other_comments[:5]:\n",
    "    print(row)\n",
    "print('\\n')\n",
    "print(\"All posts: {aposts:,}\".format(aposts=len(hn_comments)))\n",
    "print(\"All posts average comments: {avg:.2f}\".format(avg=hn_avg_comments))\n",
    "print(\"All posts average points: {:.2f}\".format(average_calc(hn_comments, 3)))\n",
    "for row in hn_comments[:5]:\n",
    "    print(row)\n",
    "    \n",
    "## post stats including no engagement\n",
    "string_format = \"In the scraped data, including posts with no direct engagement, there are {ask:,} \\\"Ask HN\\\" posts, {show:,} \\\"Show HN\\\" posts, {otter:,} \\\"other posts\\\", and a total of {totes:,} posts.\"\n",
    "string_output = string_format.format(ask=len(ask_posts), show=len(show_posts), otter=len(other_posts), totes=len(hn))\n",
    "print(string_output, '\\n')\n",
    "print(\"An overview of posts, including posts without direct engagement:\")\n",
    "print(\"Ask HN posts: {aposts:,}\".format(aposts=len(ask_posts)))\n",
    "print(\"Ask HN average comments: {avg:.2f}\".format(avg=avg_ask_posts))\n",
    "print(\"Ask HN average points: {:.2f}\".format(average_calc(ask_posts, 3)))\n",
    "for row in ask_posts[:5]:\n",
    "    print(row)\n",
    "print('\\n')\n",
    "print(\"Show HN posts: {aposts:,}\".format(aposts=len(show_posts)))\n",
    "print(\"Show HN average comments: {avg:.2f}\".format(avg=avg_show_posts))\n",
    "print(\"Show HN average points: {:.2f}\".format(average_calc(show_posts, 3)))\n",
    "for row in show_posts[:5]:\n",
    "    print(row)\n",
    "print('\\n')\n",
    "print(\"Other posts: {aposts:,}\".format(aposts=len(other_posts)))\n",
    "print(\"Other average comments: {avg:.2f}\".format(avg=avg_other_posts))\n",
    "print(\"Other posts average points: {:.2f}\".format(average_calc(other_posts, 3)))\n",
    "for row in show_posts[:5]:\n",
    "    print(row)\n",
    "print('\\n')\n",
    "print(\"All posts: {aposts:,}\".format(aposts=len(hn)))\n",
    "print(\"All posts average comments: {avg:.2f}\".format(avg=avg_all))\n",
    "print(\"All posts average points: {:.2f}\".format(average_calc(hn, 3)))\n",
    "for row in hn[:5]:\n",
    "    print(row)\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb12fb99",
   "metadata": {},
   "source": [
    "### a look at engagement via comments\n",
    "\n",
    "\"Ask HN\" posts have consistent average engagement across posts on HackerNews. This includes consistent, average engagement when including and excluding no-engagement posts in the calculation.\n",
    "\n",
    "Engagement in this context means another user has seen the post and commented on it. One can presume eyeballs have seen many of the Show HN posts, but not commented on it. One can not presume the same for the \"others\" category.\n",
    "\n",
    "|---|Excludes zero-comment posts |---|---|Includes zero-comment posts |---|---\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "|Post Type |Post Count |Average Comments |Average Points |Post Count |Average Comments |Average Points\n",
    "|Ask HN |6,911 |13.74 |14.40 |9,139 |10.39 |11.31\n",
    "|Show HN |5,059 |9.81 |26.62 |10,158 |4.89 |14.84\n",
    "|Others |68,431 |25.84 |53.43 |273,822 |6.46 |15.16\n",
    "|Total |80,401 |23.79 |48.39 |293,119 |6.53 |15.03\n",
    "\n",
    "From the above chart, one can see there is potential for high-engagement in non-\"Ask HN\" and non-\"Show HN\" posts. However, there is a stark contrast in average engagement between including and excluding zero-comment posts.\n",
    "\n",
    "Ask HN posts show the most consistent, direct engagement across the two categories. These posts generally represent a \"safe bet\" for creating a post that receives engagement from other users. Of all the Ask HN posts, 75 percent of those received direct user engagement.\n",
    "\n",
    "Show HN posts are nearer a coin-flip of whether a user will directly engage with the post. About 50 percent of Show HN posts received direct engagement.\n",
    "\n",
    "Posts in the \"other\" category have the potential for the highest engagement, but represent a significant gamble. Only about 30 percent of those posts received engagement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fc027bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pt 5 and pt 6 and pt 7 sorta\n",
    "# generate freq tables for posts per hour and comments per hour\n",
    "# use freq tables to calc avg comments per hour\n",
    "# useable for points by hour, also\n",
    "def hourly_comments(dataset, index_comments):\n",
    "    results = []\n",
    "    #loop over dataset, append to list of lists\n",
    "    for t in dataset:\n",
    "        results.append([t[6], int(t[index_comments])])\n",
    "    counts_by_hour = {}\n",
    "    comments_by_hour = {}\n",
    "    # loop over new list of lists, populate dictionary, parse string for datetime\n",
    "    for x in results:\n",
    "        x[0] = dt.datetime.strptime(x[0], \"%m/%d/%Y %H:%M\")\n",
    "        hour = x[0].hour\n",
    "        if hour in counts_by_hour:\n",
    "            counts_by_hour[hour] += 1\n",
    "            comments_by_hour[hour] += x[1]\n",
    "        else:\n",
    "            counts_by_hour[hour] = 1\n",
    "            comments_by_hour[hour] = x[1]\n",
    "    avg_by_hour = []\n",
    "    # populate list of lists while calcing an average and appending it to aforementioned list\n",
    "    for i in counts_by_hour:\n",
    "        avg_by_hour.append([comments_by_hour[i]/counts_by_hour[i],i])\n",
    "    #sorts list of lists by hour is descending order\n",
    "    sorted_avg = sorted(avg_by_hour, reverse=True)\n",
    "    return sorted_avg\n",
    "\n",
    "## exclusion of zero-comment submissions\n",
    "## calc the average comments during a given hour in the day\n",
    "# ask posts\n",
    "ex_hourly_ask = hourly_comments(ask_comments, 4)\n",
    "# show posts\n",
    "ex_hourly_show = hourly_comments(show_comments, 4)\n",
    "# other posts\n",
    "ex_hourly_other = hourly_comments(other_comments, 4)\n",
    "# all posts\n",
    "ex_hourly_hn_comments = hourly_comments(hn_comments, 4)\n",
    "## inclusion of zero-comment submissions\n",
    "## calc the average comments during a given hour in the day\n",
    "# ask posts\n",
    "in_hourly_ask = hourly_comments(ask_posts, 4)\n",
    "# show posts\n",
    "in_hourly_show = hourly_comments(show_posts, 4)\n",
    "# other posts\n",
    "in_hourly_other = hourly_comments(other_posts, 4)\n",
    "# all posts\n",
    "in_hourly_hn = hourly_comments(hn, 4)\n",
    "\n",
    "##using hourly comments function to calc avg pts per hour\n",
    "## exclusion of zero-comment submissions\n",
    "# ask posts\n",
    "ex_points_ask = hourly_comments(ask_comments, 3)\n",
    "# show posts\n",
    "ex_points_show = hourly_comments(show_comments, 3)\n",
    "# other posts\n",
    "ex_points_other = hourly_comments(other_comments, 3)\n",
    "# all posts\n",
    "ex_points_hn_comments = hourly_comments(hn_comments, 3)\n",
    "## inclusion of zero-comment submissions\n",
    "## calc the average comments during a given hour in the day\n",
    "# ask posts\n",
    "in_points_ask = hourly_comments(ask_posts, 3)\n",
    "# show posts\n",
    "in_points_show = hourly_comments(show_posts, 3)\n",
    "# other posts\n",
    "in_points_other = hourly_comments(other_posts, 3)\n",
    "# all posts\n",
    "in_points_hn = hourly_comments(hn, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "917f11f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An overview of average, high-engagement hours for posts, excluding zero-comment submissions. \n",
      "\n",
      "Ask HN: Hours of the average highest engagement\n",
      "15:00: 39.67 average comments per post.\n",
      "13:00: 22.22 average comments per post.\n",
      "12:00: 15.45 average comments per post.\n",
      "10:00: 13.76 average comments per post.\n",
      "17:00: 13.73 average comments per post.\n",
      "\n",
      "\n",
      "Show HN: Hours of the average highest engagement\n",
      "07:00: 12.42 average comments per post.\n",
      "12:00: 12.03 average comments per post.\n",
      "14:00: 11.60 average comments per post.\n",
      "08:00: 11.07 average comments per post.\n",
      "04:00: 10.87 average comments per post.\n",
      "\n",
      "\n",
      "Other posts: Hours of the average highest engagement\n",
      "13:00: 29.37 average comments per post.\n",
      "12:00: 29.20 average comments per post.\n",
      "14:00: 28.09 average comments per post.\n",
      "15:00: 27.97 average comments per post.\n",
      "11:00: 27.13 average comments per post.\n",
      "\n",
      "\n",
      "All HN: Hours of the average highest engagement\n",
      "15:00: 27.63 average comments per post.\n",
      "13:00: 27.31 average comments per post.\n",
      "12:00: 26.76 average comments per post.\n",
      "14:00: 25.66 average comments per post.\n",
      "11:00: 24.62 average comments per post.\n",
      "\n",
      "\n",
      "An overview of the average highest points for a post, excluding zero-comment submissions. \n",
      "\n",
      "Ask HN: hours of the highest engagement vis-a-vis up/downvotes\n",
      "15:00: 29.31 average points per post.\n",
      "13:00: 23.77 average points per post.\n",
      "17:00: 16.96 average points per post.\n",
      "10:00: 16.71 average points per post.\n",
      "12:00: 16.53 average points per post.\n",
      "\n",
      "\n",
      "Show HN: hours of the highest engagement vis-a-vis up/downvotes\n",
      "12:00: 33.57 average points per post.\n",
      "11:00: 31.57 average points per post.\n",
      "23:00: 30.40 average points per post.\n",
      "19:00: 29.80 average points per post.\n",
      "06:00: 29.38 average points per post.\n",
      "\n",
      "\n",
      "Other posts: hours of the highest engagement vis-a-vis up/downvotes\n",
      "13:00: 58.62 average points per post.\n",
      "12:00: 57.53 average points per post.\n",
      "15:00: 55.95 average points per post.\n",
      "17:00: 55.64 average points per post.\n",
      "16:00: 55.62 average points per post.\n",
      "\n",
      "\n",
      "All HN: hours of the highest engagement vis-a-vis up/downvotes\n",
      "13:00: 53.61 average points per post.\n",
      "12:00: 52.49 average points per post.\n",
      "15:00: 51.11 average points per post.\n",
      "17:00: 50.46 average points per post.\n",
      "16:00: 50.00 average points per post.\n",
      "\n",
      "\n",
      "An overview of average, high-engagement hours for posts, including zero-comment submissions. \n",
      "\n",
      "Ask HN: Hours of the average highest engagement\n",
      "15:00: 28.68 average comments per post.\n",
      "13:00: 16.32 average comments per post.\n",
      "12:00: 12.38 average comments per post.\n",
      "02:00: 11.14 average comments per post.\n",
      "10:00: 10.68 average comments per post.\n",
      "\n",
      "\n",
      "Show HN: Hours of the average highest engagement\n",
      "12:00: 6.99 average comments per post.\n",
      "07:00: 6.68 average comments per post.\n",
      "11:00: 6.00 average comments per post.\n",
      "08:00: 5.60 average comments per post.\n",
      "14:00: 5.52 average comments per post.\n",
      "\n",
      "\n",
      "Other posts: Hours of the average highest engagement\n",
      "12:00: 7.59 average comments per post.\n",
      "11:00: 7.37 average comments per post.\n",
      "02:00: 7.18 average comments per post.\n",
      "13:00: 7.15 average comments per post.\n",
      "05:00: 6.79 average comments per post.\n",
      "\n",
      "\n",
      "All HN: Hours of the average highest engagement\n",
      "12:00: 7.69 average comments per post.\n",
      "11:00: 7.37 average comments per post.\n",
      "13:00: 7.34 average comments per post.\n",
      "02:00: 7.27 average comments per post.\n",
      "15:00: 7.05 average comments per post.\n",
      "\n",
      "\n",
      "An overview of the average highest points for a post, including zero-comment submissions. \n",
      "\n",
      "Ask HN: hours of the highest engagement vis-a-vis up/downvotes\n",
      "15:00: 21.64 average points per post.\n",
      "13:00: 17.93 average points per post.\n",
      "12:00: 13.58 average points per post.\n",
      "10:00: 13.44 average points per post.\n",
      "17:00: 12.19 average points per post.\n",
      "\n",
      "\n",
      "Show HN: hours of the highest engagement vis-a-vis up/downvotes\n",
      "12:00: 20.91 average points per post.\n",
      "11:00: 19.26 average points per post.\n",
      "13:00: 17.02 average points per post.\n",
      "19:00: 16.06 average points per post.\n",
      "06:00: 15.99 average points per post.\n",
      "\n",
      "\n",
      "Other posts: hours of the highest engagement vis-a-vis up/downvotes\n",
      "02:00: 16.71 average points per post.\n",
      "12:00: 16.70 average points per post.\n",
      "11:00: 16.29 average points per post.\n",
      "00:00: 16.12 average points per post.\n",
      "13:00: 16.02 average points per post.\n",
      "\n",
      "\n",
      "All HN: hours of the highest engagement vis-a-vis up/downvotes\n",
      "12:00: 16.79 average points per post.\n",
      "02:00: 16.41 average points per post.\n",
      "11:00: 16.19 average points per post.\n",
      "13:00: 16.11 average points per post.\n",
      "00:00: 15.88 average points per post.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## posts excluding zero-comment submissions, comments\n",
    "print(\"An overview of average, high-engagement hours for posts, excluding zero-comment submissions.\", '\\n')\n",
    "print(\"Ask HN: Hours of the average highest engagement\")\n",
    "for item in ex_hourly_ask[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {comments:.2f} average comments per post.\".format(hour=item[1], comments=item[0])\n",
    "    print(strang)\n",
    "print('\\n')    \n",
    "print(\"Show HN: Hours of the average highest engagement\")\n",
    "for item in ex_hourly_show[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {comments:.2f} average comments per post.\".format(hour=item[1], comments=item[0])\n",
    "    print(strang)\n",
    "print('\\n')    \n",
    "print(\"Other posts: Hours of the average highest engagement\")\n",
    "for item in ex_hourly_other[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {comments:.2f} average comments per post.\".format(hour=item[1], comments=item[0])\n",
    "    print(strang)\n",
    "print('\\n')    \n",
    "print(\"All HN: Hours of the average highest engagement\")\n",
    "for item in ex_hourly_hn_comments[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {comments:.2f} average comments per post.\".format(hour=item[1], comments=item[0])\n",
    "    print(strang)\n",
    "print('\\n')\n",
    "\n",
    "# posts excluding zero-comment submissions, points\n",
    "print(\"An overview of the average highest points for a post, excluding zero-comment submissions.\", '\\n')\n",
    "print(\"Ask HN: hours of the highest engagement vis-a-vis up/downvotes\")\n",
    "for item in ex_points_ask[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {points:.2f} average points per post.\".format(hour=item[1], points=item[0])\n",
    "    print(strang)\n",
    "print('\\n')\n",
    "print(\"Show HN: hours of the highest engagement vis-a-vis up/downvotes\")\n",
    "for item in ex_points_show[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {points:.2f} average points per post.\".format(hour=item[1], points=item[0])\n",
    "    print(strang)\n",
    "print('\\n')\n",
    "print(\"Other posts: hours of the highest engagement vis-a-vis up/downvotes\")\n",
    "for item in ex_points_other[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {points:.2f} average points per post.\".format(hour=item[1], points=item[0])\n",
    "    print(strang)\n",
    "print('\\n')\n",
    "print(\"All HN: hours of the highest engagement vis-a-vis up/downvotes\")\n",
    "for item in ex_points_hn_comments[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {points:.2f} average points per post.\".format(hour=item[1], points=item[0])\n",
    "    print(strang)\n",
    "print('\\n')\n",
    "\n",
    "# posts including zero-comment submissions, comments\n",
    "print(\"An overview of average, high-engagement hours for posts, including zero-comment submissions.\", '\\n')\n",
    "print(\"Ask HN: Hours of the average highest engagement\")\n",
    "for item in in_hourly_ask[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {comments:.2f} average comments per post.\".format(hour=item[1], comments=item[0])\n",
    "    print(strang)\n",
    "print('\\n')    \n",
    "print(\"Show HN: Hours of the average highest engagement\")\n",
    "for item in in_hourly_show[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {comments:.2f} average comments per post.\".format(hour=item[1], comments=item[0])\n",
    "    print(strang)\n",
    "print('\\n')    \n",
    "print(\"Other posts: Hours of the average highest engagement\")\n",
    "for item in in_hourly_other[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {comments:.2f} average comments per post.\".format(hour=item[1], comments=item[0])\n",
    "    print(strang)\n",
    "print('\\n')    \n",
    "print(\"All HN: Hours of the average highest engagement\")\n",
    "for item in in_hourly_hn[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {comments:.2f} average comments per post.\".format(hour=item[1], comments=item[0])\n",
    "    print(strang)\n",
    "print('\\n')\n",
    "\n",
    "#posts including zero-comment submission, points\n",
    "print(\"An overview of the average highest points for a post, including zero-comment submissions.\", '\\n')\n",
    "print(\"Ask HN: hours of the highest engagement vis-a-vis up/downvotes\")\n",
    "for item in in_points_ask[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {points:.2f} average points per post.\".format(hour=item[1], points=item[0])\n",
    "    print(strang)\n",
    "print('\\n')\n",
    "print(\"Show HN: hours of the highest engagement vis-a-vis up/downvotes\")\n",
    "for item in in_points_show[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {points:.2f} average points per post.\".format(hour=item[1], points=item[0])\n",
    "    print(strang)\n",
    "print('\\n')\n",
    "print(\"Other posts: hours of the highest engagement vis-a-vis up/downvotes\")\n",
    "for item in in_points_other[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {points:.2f} average points per post.\".format(hour=item[1], points=item[0])\n",
    "    print(strang)\n",
    "print('\\n')\n",
    "print(\"All HN: hours of the highest engagement vis-a-vis up/downvotes\")\n",
    "for item in in_points_hn[:5]:\n",
    "    item[1] = dt.datetime.strptime(str(item[1]), '%H').strftime('%H:%M')\n",
    "    strang = \"{hour}: {points:.2f} average points per post.\".format(hour=item[1], points=item[0])\n",
    "    print(strang)\n",
    "print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
